{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8cc53e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5f420ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"datasets\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "727b6db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_MANIFEST = os.path.join(data_dir,'train_manifest.json')\n",
    "TEST_MANIFEST = os.path.join(data_dir, 'test_manifest.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92dd7147",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 1024  # can be any value above 29\n",
    "TOKENIZER_TYPE = \"spe\"  # can be wpe or spe\n",
    "SPE_TYPE = \"unigram\"  # can be bpe or unigram\n",
    "\n",
    "# # ------------------------------------------------------------------- #\n",
    "# !rm -r tokenizers/\n",
    "\n",
    "# if not os.path.exists(\"tokenizers\"):\n",
    "#   os.makedirs(\"tokenizers\")\n",
    "\n",
    "# !python scripts/process_asr_text_tokenizer.py \\\n",
    "#    --manifest=$TRAIN_MANIFEST \\\n",
    "#    --data_root=\"tokenizers\" \\\n",
    "#    --tokenizer=$TOKENIZER_TYPE \\\n",
    "#    --spe_type=$SPE_TYPE \\\n",
    "#    --no_lower_case \\\n",
    "#    --log \\\n",
    "#    --vocab_size=$VOCAB_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a9d16b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizer path\n",
    "if TOKENIZER_TYPE == 'spe':\n",
    "  TOKENIZER = os.path.join(\"tokenizers\", f\"tokenizer_spe_{SPE_TYPE}_v{VOCAB_SIZE}\")\n",
    "  TOKENIZER_TYPE_CFG = \"bpe\"\n",
    "else:\n",
    "  TOKENIZER = os.path.join(\"tokenizers\", f\"tokenizer_wpe_v{VOCAB_SIZE}\")\n",
    "  TOKENIZER_TYPE_CFG = \"wpe\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1beeb2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from omegaconf import OmegaConf, open_dict\n",
    "\n",
    "config = OmegaConf.load(\"./configs/conformer_transducer_bpe_small.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8bfbc5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config.model.encoder.jasper[-1].filters = '${model.model_defaults.enc_hidden}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "534ca6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.model.train_ds.manifest_filepath = TRAIN_MANIFEST\n",
    "config.model.validation_ds.manifest_filepath = TEST_MANIFEST\n",
    "config.model.test_ds.manifest_filepath = TEST_MANIFEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a13709b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "manifest_filepath: datasets/train_manifest.json\n",
      "sample_rate: ${model.sample_rate}\n",
      "batch_size: 16\n",
      "shuffle: true\n",
      "num_workers: 8\n",
      "pin_memory: true\n",
      "use_start_end_token: false\n",
      "trim_silence: false\n",
      "max_duration: 16.7\n",
      "min_duration: 0.1\n",
      "is_tarred: false\n",
      "tarred_audio_filepaths: null\n",
      "shuffle_n: 2048\n",
      "bucketing_strategy: synced_randomized\n",
      "bucketing_batch_size: null\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print out the train and validation configs to know what needs to be changed\n",
    "print(OmegaConf.to_yaml(config.model.train_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "56969053",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.model.tokenizer.dir = TOKENIZER\n",
    "config.model.tokenizer.type = TOKENIZER_TYPE_CFG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "068b692d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dir: tokenizers/tokenizer_spe_unigram_v1024\n",
      "type: bpe\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(OmegaConf.to_yaml(config.model.tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ceab9b0b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: adamw\n",
      "lr: 0.5\n",
      "betas:\n",
      "- 0.9\n",
      "- 0.98\n",
      "weight_decay: 0.0\n",
      "sched:\n",
      "  name: NoamAnnealing\n",
      "  d_model: ${model.encoder.d_model}\n",
      "  warmup_steps: 10000\n",
      "  warmup_ratio: null\n",
      "  min_lr: 1.0e-06\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(OmegaConf.to_yaml(config.model.optim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d3991ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, let's remove logging of samples and the warmup since the dataset is small (similar to CTC models)\n",
    "config.model.log_prediction = False\n",
    "config.model.optim.sched.warmup_steps = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6bea1b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.model.spec_augment.freq_masks = 0\n",
    "config.model.spec_augment.time_masks = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cc141762",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_target_: nemo.collections.asr.modules.SpectrogramAugmentation\n",
      "freq_masks: 0\n",
      "time_masks: 0\n",
      "freq_width: 27\n",
      "time_width: 0.05\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(OmegaConf.to_yaml(config.model.spec_augment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9be79a43",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_target_: nemo.collections.asr.modules.RNNTJoint\n",
      "log_softmax: null\n",
      "preserve_memory: false\n",
      "fuse_loss_wer: true\n",
      "fused_batch_size: 16\n",
      "jointnet:\n",
      "  joint_hidden: ${model.model_defaults.joint_hidden}\n",
      "  activation: relu\n",
      "  dropout: 0.2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(OmegaConf.to_yaml(config.model.joint))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b13494d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from pytorch_lightning import Trainer\n",
    "import pytorch_lightning as ptl\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "  accelerator = 'gpu'\n",
    "else:\n",
    "  accelerator = 'cpu'\n",
    "\n",
    "EPOCHS = 100\n",
    "\n",
    "# ckpt_callback = ptl.callbacks.ModelCheckpoint(save_top_k=7)\n",
    "\n",
    "# Initialize a Trainer for the Transducer model\n",
    "trainer = Trainer(devices=1, accelerator=accelerator, max_epochs=EPOCHS,\n",
    "                  enable_checkpointing=False, logger=False,\n",
    "                  log_every_n_steps=100, check_val_every_n_epoch=1,accumulate_grad_batches=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0a11e3a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2022-09-19 08:24:54 optimizers:55] Apex was not found. Using the lamb or fused_adam optimizer will error out.\n"
     ]
    }
   ],
   "source": [
    "import nemo.collections.asr as nemo_asr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b23899ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2022-09-19 08:24:59 mixins:170] Tokenizer SentencePieceTokenizer initialized with 1024 tokens\n",
      "[NeMo I 2022-09-19 08:25:07 collections:194] Dataset loaded with 49759 files totalling 83.57 hours\n",
      "[NeMo I 2022-09-19 08:25:07 collections:195] 0 files were filtered totalling 0.00 hours\n",
      "[NeMo I 2022-09-19 08:25:07 collections:194] Dataset loaded with 2685 files totalling 4.38 hours\n",
      "[NeMo I 2022-09-19 08:25:07 collections:195] 0 files were filtered totalling 0.00 hours\n",
      "[NeMo I 2022-09-19 08:25:08 collections:194] Dataset loaded with 2685 files totalling 4.38 hours\n",
      "[NeMo I 2022-09-19 08:25:08 collections:195] 0 files were filtered totalling 0.00 hours\n",
      "[NeMo I 2022-09-19 08:25:08 features:223] PADDING: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2022-09-19 08:25:08 nemo_logging:349] /home/user/TRANSDUCER_r1.11.0/env/lib/python3.8/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "      warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2022-09-19 08:25:08 rnnt_models:203] Using RNNT Loss : warprnnt_numba\n",
      "    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}\n",
      "[NeMo I 2022-09-19 08:25:08 audio_preprocessing:491] Numba CUDA SpecAugment kernel is being used\n"
     ]
    }
   ],
   "source": [
    "# Build the model\n",
    "model = nemo_asr.models.EncDecRNNTBPEModel(cfg=config.model, trainer=trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ccc12c69",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  | Name              | Type                              | Params\n",
       "------------------------------------------------------------------------\n",
       "0 | preprocessor      | AudioToMelSpectrogramPreprocessor | 0     \n",
       "1 | encoder           | ConformerEncoder                  | 13.0 M\n",
       "2 | decoder           | RNNTDecoder                       | 1.1 M \n",
       "3 | joint             | RNNTJoint                         | 488 K \n",
       "4 | loss              | RNNTLoss                          | 0     \n",
       "5 | spec_augmentation | SpectrogramAugmentation           | 0     \n",
       "6 | wer               | RNNTBPEWER                        | 0     \n",
       "------------------------------------------------------------------------\n",
       "14.6 M    Trainable params\n",
       "0         Non-trainable params\n",
       "14.6 M    Total params\n",
       "58.443    Total estimated model params size (MB)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.summarize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "917c552b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2022-09-19 08:25:19 cloud:56] Found existing object /home/user/.cache/torch/NeMo/NeMo_1.11.0/stt_en_conformer_transducer_small/a755afe69952642a8410330876938b83/stt_en_conformer_transducer_small.nemo.\n",
      "[NeMo I 2022-09-19 08:25:19 cloud:62] Re-using file from: /home/user/.cache/torch/NeMo/NeMo_1.11.0/stt_en_conformer_transducer_small/a755afe69952642a8410330876938b83/stt_en_conformer_transducer_small.nemo\n",
      "[NeMo I 2022-09-19 08:25:19 common:910] Instantiating model from pre-trained checkpoint\n",
      "[NeMo I 2022-09-19 08:25:21 mixins:170] Tokenizer SentencePieceTokenizer initialized with 1024 tokens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2022-09-19 08:25:21 modelPT:142] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    manifest_filepath: /data2/nemo_asr_set_2.0/RES/tarred_audio_manifest.json\n",
      "    sample_rate: 16000\n",
      "    batch_size: 16\n",
      "    shuffle: true\n",
      "    num_workers: 4\n",
      "    pin_memory: true\n",
      "    use_start_end_token: true\n",
      "    trim_silence: false\n",
      "    max_duration: 20\n",
      "    min_duration: 0.1\n",
      "    shuffle_n: 2048\n",
      "    is_tarred: true\n",
      "    tarred_audio_filepaths: /data2/nemo_asr_set_2.0/RES/audio__OP_0..4095_CL_.tar\n",
      "    \n",
      "[NeMo W 2022-09-19 08:25:21 modelPT:149] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    manifest_filepath:\n",
      "    - /manifests/librispeech/librivox-dev-other.json\n",
      "    - /manifests/librispeech/librivox-dev-clean.json\n",
      "    - /manifests/librispeech/librivox-test-other.json\n",
      "    - /manifests/librispeech/librivox-test-clean.json\n",
      "    sample_rate: 16000\n",
      "    batch_size: 16\n",
      "    shuffle: false\n",
      "    num_workers: 8\n",
      "    pin_memory: true\n",
      "    use_start_end_token: true\n",
      "    is_tarred: false\n",
      "    tarred_audio_filepaths: na\n",
      "    \n",
      "[NeMo W 2022-09-19 08:25:21 modelPT:155] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
      "    Test config : \n",
      "    manifest_filepath:\n",
      "    - /manifests/librispeech/librivox-dev-other.json\n",
      "    - /manifests/librispeech/librivox-dev-clean.json\n",
      "    - /manifests/librispeech/librivox-test-other.json\n",
      "    - /manifests/librispeech/librivox-test-clean.json\n",
      "    sample_rate: 16000\n",
      "    batch_size: 16\n",
      "    shuffle: false\n",
      "    num_workers: 8\n",
      "    pin_memory: true\n",
      "    use_start_end_token: true\n",
      "    is_tarred: false\n",
      "    tarred_audio_filepaths: na\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2022-09-19 08:25:21 features:223] PADDING: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2022-09-19 08:25:22 nemo_logging:349] /home/user/TRANSDUCER_r1.11.0/env/lib/python3.8/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "      warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2022-09-19 08:25:22 rnnt_models:203] Using RNNT Loss : warprnnt_numba\n",
      "    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0}\n",
      "[NeMo I 2022-09-19 08:25:22 audio_preprocessing:491] Numba CUDA SpecAugment kernel is being used\n",
      "[NeMo I 2022-09-19 08:25:31 save_restore_connector:243] Model EncDecRNNTBPEModel was successfully restored from /home/user/.cache/torch/NeMo/NeMo_1.11.0/stt_en_conformer_transducer_small/a755afe69952642a8410330876938b83/stt_en_conformer_transducer_small.nemo.\n"
     ]
    }
   ],
   "source": [
    "asr_model = nemo_asr.models.EncDecRNNTBPEModel.from_pretrained(model_name=\"stt_en_conformer_transducer_small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b0f826",
   "metadata": {},
   "outputs": [],
   "source": [
    "# asr_model = nemo_asr.models.EncDecRNNTBPEModel.load_from_checkpoint('/home/user/TRANSDUCER_r1.11.0/EXP1/experiments/Transducer-Model-UZ-finetuning-Contextnet/2022-09-16_06-36-25/checkpoints/Transducer-Model-UZ-finetuning-Contextnet--val_wer=0.3657-epoch=2.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f4ac4a4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.encoder.load_state_dict(asr_model.encoder.state_dict(), strict=True)\n",
    "\n",
    "model.decoder.load_state_dict(asr_model.decoder.state_dict(), strict=True)\n",
    "\n",
    "model.joint.load_state_dict(asr_model.joint.state_dict(), strict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d062ac79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2022-09-19 08:25:39 exp_manager:286] Experiments will be logged at experiments/Transducer-Model-UZ-finetuning-Conformer-Transducer/2022-09-19_08-25-39\n",
      "[NeMo I 2022-09-19 08:25:39 exp_manager:660] TensorboardLogger has been set up\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2022-09-19 08:25:39 nemo_logging:349] /home/user/TRANSDUCER_r1.11.0/env/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:2319: LightningDeprecationWarning: `Trainer.weights_save_path` has been deprecated in v1.6 and will be removed in v1.8.\n",
      "      rank_zero_deprecation(\"`Trainer.weights_save_path` has been deprecated in v1.6 and will be removed in v1.8.\")\n",
      "    \n",
      "[NeMo W 2022-09-19 08:25:39 exp_manager:899] The checkpoint callback was told to monitor a validation value and trainer's max_steps was set to -1. Please ensure that max_steps will run for at least 1 epochs to ensure that checkpointing will not error out.\n"
     ]
    }
   ],
   "source": [
    "# Prepare NeMo's Experiment manager to handle checkpoint saving and logging for us\n",
    "from nemo.utils import exp_manager\n",
    "\n",
    "# Environment variable generally used for multi-node multi-gpu training.\n",
    "# In notebook environments, this flag is unnecessary and can cause logs of multiple training runs to overwrite each other.\n",
    "os.environ.pop('NEMO_EXPM_VERSION', None)\n",
    "\n",
    "exp_config = exp_manager.ExpManagerConfig(\n",
    "    exp_dir=f'experiments/',\n",
    "    name=f\"Transducer-Model-UZ-finetuning-Conformer-Transducer\",\n",
    "    checkpoint_callback_params=exp_manager.CallbackParams(\n",
    "        monitor=\"val_wer\",\n",
    "        mode=\"min\",\n",
    "        always_save_nemo=True,\n",
    "        save_best_model=True,\n",
    "    ),\n",
    ")\n",
    "\n",
    "exp_config = OmegaConf.structured(exp_config)\n",
    "\n",
    "logdir = exp_manager.exp_manager(trainer, exp_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "084c0b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !tensorboard --bind_all --logdir ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5f8d6fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Release resources prior to training\n",
    "import gc\n",
    "gc.collect()\n",
    "\n",
    "if accelerator == 'gpu':\n",
    "  torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bd8dd6e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2022-09-19 08:25:49 modelPT:587] Optimizer config = AdamW (\n",
      "    Parameter Group 0\n",
      "        amsgrad: False\n",
      "        betas: [0.9, 0.98]\n",
      "        capturable: False\n",
      "        eps: 1e-08\n",
      "        foreach: None\n",
      "        lr: 0.5\n",
      "        maximize: False\n",
      "        weight_decay: 0.0\n",
      "    )\n",
      "[NeMo I 2022-09-19 08:25:49 lr_scheduler:910] Scheduler \"<nemo.core.optim.lr_scheduler.NoamAnnealing object at 0x7fdd204bf4c0>\" \n",
      "    will be used during training (effective maximum steps = 311000) - \n",
      "    Parameters : \n",
      "    (d_model: 176\n",
      "    warmup_steps: null\n",
      "    warmup_ratio: null\n",
      "    min_lr: 1.0e-06\n",
      "    max_steps: 311000\n",
      "    )\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name              | Type                              | Params\n",
      "------------------------------------------------------------------------\n",
      "0 | preprocessor      | AudioToMelSpectrogramPreprocessor | 0     \n",
      "1 | encoder           | ConformerEncoder                  | 13.0 M\n",
      "2 | decoder           | RNNTDecoder                       | 1.1 M \n",
      "3 | joint             | RNNTJoint                         | 488 K \n",
      "4 | loss              | RNNTLoss                          | 0     \n",
      "5 | spec_augmentation | SpectrogramAugmentation           | 0     \n",
      "6 | wer               | RNNTBPEWER                        | 0     \n",
      "------------------------------------------------------------------------\n",
      "14.6 M    Trainable params\n",
      "0         Non-trainable params\n",
      "14.6 M    Total params\n",
      "58.443    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.018456220626831055,
       "initial": 0,
       "n": 0,
       "ncols": 158,
       "nrows": 24,
       "postfix": null,
       "prefix": "Sanity Checking",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.022905349731445312,
       "initial": 0,
       "n": 0,
       "ncols": 158,
       "nrows": 24,
       "postfix": null,
       "prefix": "Training",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69f058fa4a41496db942fd06918549e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.01882338523864746,
       "initial": 0,
       "n": 0,
       "ncols": 158,
       "nrows": 24,
       "postfix": null,
       "prefix": "Validation",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 3110: 'val_wer' reached 1.00000 (best 1.00000), saving model to '/home/user/TRANSDUCER_r1.11.0/EXP1/experiments/Transducer-Model-UZ-finetuning-Conformer-Transducer/2022-09-19_08-25-39/checkpoints/Transducer-Model-UZ-finetuning-Conformer-Transducer--val_wer=1.0000-epoch=0.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.02049732208251953,
       "initial": 0,
       "n": 0,
       "ncols": 158,
       "nrows": 24,
       "postfix": null,
       "prefix": "Validation",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 6220: 'val_wer' reached 1.00000 (best 1.00000), saving model to '/home/user/TRANSDUCER_r1.11.0/EXP1/experiments/Transducer-Model-UZ-finetuning-Conformer-Transducer/2022-09-19_08-25-39/checkpoints/Transducer-Model-UZ-finetuning-Conformer-Transducer--val_wer=1.0000-epoch=1.ckpt' as top 3\n",
      "[NeMo W 2022-09-19 09:00:17 nemo_logging:349] /home/user/TRANSDUCER_r1.11.0/env/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:726: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "      rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d05866",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer.test(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
